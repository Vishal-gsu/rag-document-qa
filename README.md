# ğŸ¤– Intelligent Document Q&A System with RAG

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/Docker-Required-blue)](https://www.docker.com/)
[![Contact](https://img.shields.io/badge/Email-vishalgsu%40gmail.com-red)](mailto:vishalgsu@gmail.com)

A **production-ready Retrieval Augmented Generation (RAG)** system that lets you chat with your documents using AI. Upload PDFs, Word docs, or text files and ask questions - get accurate, cited answers in seconds!

![RAG Architecture](https://img.shields.io/badge/Architecture-RAG-green) ![Vector DB](https://img.shields.io/badge/VectorDB-Endee%20HNSW-orange) ![LLM](https://img.shields.io/badge/LLM-4%20Options-purple) ![Embeddings](https://img.shields.io/badge/Embeddings-BGE--1024D-brightgreen)

> **ğŸ“Œ Built with [Endee Vector Database](https://github.com/EndeeLabs/endee)** | [My Forked Repository](https://github.com/Vishal-gsu/endee)
> 
> **ğŸ‘¨â€ğŸ’» Developer:** Vishal Kumar | **ğŸ“§ Contact:** vishalgsu@gmail.com

---

## âœ¨ Features

- ğŸ” **Semantic Search** - Find relevant information using AI-powered similarity search
- ğŸ“„ **Multi-Format Support** - PDF, DOCX, TXT, Markdown files
- âš¡ **Fast Retrieval** - HNSW algorithm for sub-second search (O(log n) complexity)
- ğŸ¤– **Multiple LLM Options** - Choose from Groq (FREE), OpenAI, or local Ollama
- ğŸ’¾ **Persistent Storage** - Your documents stay indexed across sessions
- ğŸ¨ **Interactive UI** - Beautiful Streamlit interface with 4 tabs
- ğŸ§ª **Testing Suite** - 6 interactive tests for embeddings, similarity, and search quality
- ğŸ“Š **Performance Metrics** - Track retrieval accuracy and response times

---

## ğŸ¯ How It Works - Complete RAG Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DOCUMENT INDEXING PHASE                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  ğŸ“„ PDF/DOCX/TXT Files                                                 â”‚
â”‚         â†“                                                               â”‚
â”‚  ğŸ”§ Document Processor (PyPDF2, python-docx)                          â”‚
â”‚         â†“                                                               â”‚
â”‚  ğŸ”ª Text Chunker (1000 chars, 200 overlap)                            â”‚
â”‚         â†“                                                               â”‚
â”‚  ğŸ§  Embedding Engine (BAAI/bge-large-en-v1.5)                         â”‚
â”‚         â†“                                                               â”‚
â”‚  ğŸ“Š 1024-dimensional vectors                                           â”‚
â”‚         â†“                                                               â”‚
â”‚  ğŸ’¾ Endee Vector DB (HNSW Index)                                       â”‚
â”‚     â€¢ Layer 2: Long-range connections (sparse)                         â”‚
â”‚     â€¢ Layer 1: Medium-range connections                                â”‚
â”‚     â€¢ Layer 0: All vectors (dense graph)                               â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         QUERY PROCESSING PHASE                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  ğŸ’­ User Question: "What is machine learning?"                         â”‚
â”‚         â†“                                                               â”‚
â”‚  ğŸ§  Same Embedding Model (BAAI/bge-large-en-v1.5)                      â”‚
â”‚         â†“                                                               â”‚
â”‚  ğŸ“Š Query Vector [1024 dimensions]                                     â”‚
â”‚         â†“                                                               â”‚
â”‚  ğŸ” Endee HNSW Search                                                   â”‚
â”‚     â€¢ Start at top layer (Layer 2)                                     â”‚
â”‚     â€¢ Navigate to nearest neighbors                                     â”‚
â”‚     â€¢ Descend to Layer 1, refine search                                â”‚
â”‚     â€¢ Final search at Layer 0 (base layer)                             â”‚
â”‚     â€¢ Time Complexity: O(log n) - FAST! âš¡                             â”‚
â”‚         â†“                                                               â”‚
â”‚  ğŸ“š Top-5 Most Similar Chunks                                          â”‚
â”‚     Chunk 1: 0.87 similarity                                           â”‚
â”‚     Chunk 2: 0.82 similarity                                           â”‚
â”‚     Chunk 3: 0.78 similarity                                           â”‚
â”‚     Chunk 4: 0.71 similarity                                           â”‚
â”‚     Chunk 5: 0.68 similarity                                           â”‚
â”‚         â†“                                                               â”‚
â”‚  ğŸ“ Prompt Template                                                     â”‚
â”‚     Context: [Retrieved chunks]                                        â”‚
â”‚     Question: [User question]                                          â”‚
â”‚     Instructions: Answer based on context only                         â”‚
â”‚         â†“                                                               â”‚
â”‚  ğŸ¤– LLM (Groq/OpenAI/Ollama)                                           â”‚
â”‚         â†“                                                               â”‚
â”‚  âœ… AI-Generated Answer + Citations                                     â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ”¬ Detailed RAG Pipeline Breakdown

#### **Phase 1: Document Indexing (One-Time Setup)**

1. **ğŸ“„ Document Ingestion** 
   - Accepts PDF, DOCX, TXT, Markdown files
   - Uses PyPDF2 for PDFs, python-docx for Word docs
   - Extracts raw text while preserving structure

2. **ğŸ”ª Intelligent Chunking**
   - Chunk Size: 1000 characters (optimal for context)
   - Overlap: 200 characters (prevents information loss at boundaries)
   - Creates ~4,772 chunks from typical document set

3. **ğŸ§  Embedding Generation**
   - Model: **BAAI/bge-large-en-v1.5** (State-of-the-art)
   - Dimension: **1024D** (high semantic precision)
   - Each chunk â†’ 1024-dimensional vector
   - Captures semantic meaning, not just keywords

4. **ğŸ’¾ Vector Storage in Endee**
   - Algorithm: **HNSW (Hierarchical Navigable Small World)**
   - Creates multi-layer graph structure
   - Persistent storage using Docker volumes
   - Supports millions of vectors efficiently

#### **Phase 2: Query Processing (Every Search)**

5. **ğŸ’­ Question Embedding**
   - User asks: "What is machine learning?"
   - Same model (BAAI/bge-large-en-v1.5) converts to 1024D vector
   - **Critical:** Query and documents use same embedding space

6. **ğŸ” HNSW Similarity Search**
   - Compares query vector with document vectors
   - Uses cosine similarity metric
   - HNSW navigates graph intelligently (not brute force)
   - Finds top-5 most similar chunks in ~5ms (O(log n))
   - Filters results above 0.30 similarity threshold

7. **ğŸ¤– LLM Answer Generation**
   - Combines retrieved context + user question
   - Sends to LLM (Groq Llama/GPT-3.5/Ollama)
   - LLM generates answer based ONLY on provided context
   - Prevents hallucination by grounding in retrieved data

8. **âœ… Response with Citations**
   - Returns AI-generated answer
   - Shows source documents and similarity scores
   - User can verify information accuracy

---

## ğŸš€ Complete Installation & Setup Guide

### ğŸ“‹ Prerequisites

Before starting, ensure you have these installed:

| Requirement | Version | Download Link | Purpose |
|------------|---------|---------------|---------|
| **Python** | 3.8+ | [python.org/downloads](https://www.python.org/downloads/) | Run the application |
| **Docker Desktop** | Latest | [docker.com/products/docker-desktop](https://www.docker.com/products/docker-desktop/) | Host Endee vector database |
| **Git** | Latest | [git-scm.com/downloads](https://git-scm.com/downloads) | Clone repository |
| **8GB RAM** | Minimum | - | Run embeddings & LLM |
| **5GB Disk** | Free space | - | Store models & data |

---

### ğŸ”§ Step-by-Step Installation

#### **Step 1: Clone the Repository**

```bash
# Clone the project
git clone https://github.com/Vishal-gsu/rag-document-qa.git

# Navigate to project directory
cd rag-document-qa

# Verify files exist
ls  # Should see: app.py, requirements.txt, docker-compose.yml, etc.
```

---

#### **Step 2: Create Python Virtual Environment**

**Why?** Isolates project dependencies from system Python.

```bash
# Create virtual environment
python -m venv venv

# Expected output: Creates 'venv' folder with Python binaries
```

**Activate the environment:**

```bash
# Windows (PowerShell)
.\venv\Scripts\Activate.ps1

# Windows (Command Prompt)
venv\Scripts\activate.bat

# macOS/Linux
source venv/bin/activate

# Verify activation: Your prompt should show (venv)
# Example: (venv) PS C:\Users\YourName\rag-document-qa>
```

**Troubleshooting activation:**
- Windows: If you get execution policy error, run:
  ```powershell
  Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
  ```

---

#### **Step 3: Install Python Dependencies**

```bash
# Upgrade pip first (recommended)
python -m pip install --upgrade pip

# Install all required packages
pip install -r requirements.txt

# This installs (~2-3 minutes):
# - endee==0.1.8 (Vector database client)
# - openai, groq (LLM providers)
# - streamlit (Web interface)
# - sentence-transformers (BAAI/bge-large-en-v1.5 embeddings)
# - pypdf2, python-docx (Document parsers)
# - numpy, scikit-learn (Vector operations)
# + 20 more dependencies

# Verify installation
pip list | grep endee  # Should show: endee  0.1.8
```

**Expected time:** 2-5 minutes depending on internet speed

**Common issues:**
- If you see "No module named pip": `python -m ensurepip --upgrade`
- If numpy fails on Windows: Install Microsoft C++ Build Tools

---

#### **Step 4: Configure Environment Variables**

```bash
# Create your environment file from template
copy .env.example .env  # Windows
# cp .env.example .env  # macOS/Linux

# Open .env in your text editor
notepad .env  # Windows
# nano .env   # macOS/Linux
```

**Configure API Keys (Choose ONE option):**

**Option A: Groq API (FREE - Recommended!)**
```env
GROQ_API_KEY=gsk_your_actual_groq_api_key_here
OPENAI_API_KEY=  # Leave empty
```
- Get free key: https://console.groq.com/keys
- No credit card required
- 14,400 requests/day free tier

**Option B: OpenAI API (Paid)**
```env
GROQ_API_KEY=  # Leave empty
OPENAI_API_KEY=sk-proj-your_actual_openai_key_here
```
- Get key: https://platform.openai.com/api-keys
- Costs ~$0.002 per query

**Option C: Local Ollama (No API key needed)**
```env
GROQ_API_KEY=  # Leave empty
OPENAI_API_KEY=  # Leave empty
```
- Install Ollama separately: https://ollama.com
- Run: `ollama pull llama3.2`

**Other settings (optional):**
```env
EMBEDDING_MODEL=sentence-transformers  # Uses BAAI/bge-large-en-v1.5 (1024D)
CHUNK_SIZE=1000                        # Characters per text chunk
CHUNK_OVERLAP=200                      # Overlap between chunks
TOP_K_RESULTS=5                        # Number of chunks to retrieve
```

---

#### **Step 5: Start Endee Vector Database**

**Check Docker is running:**
```bash
docker --version  # Should show: Docker version 20.x or higher

# If Docker not running:
# Windows/Mac: Open Docker Desktop application
# Linux: sudo systemctl start docker
```

**Start Endee:**
```bash
# Start Endee server in background
docker compose up -d

# Expected output:
# [+] Running 2/2
#  âœ” Network rag-document-qa_default  Created
#  âœ” Container endee-server           Started
```

**Verify Endee is running:**
```bash
# Check container status
docker ps

# Should show:
# CONTAINER ID   IMAGE                          STATUS         PORTS
# abc123def456   endeeio/endee-server:latest   Up 10 seconds  0.0.0.0:8080->8080/tcp

# Test Endee API
curl http://localhost:8080/health
# Expected: {"status":"ok"}
```

**View Endee logs (if issues):**
```bash
docker logs endee-server -f
# Press Ctrl+C to exit logs
```

---

#### **Step 6: Launch the Application**

```bash
# Make sure you're in the project directory and venv is activated

# Run Streamlit app
streamlit run app.py

# Expected output:
#   You can now view your Streamlit app in your browser.
#
#   Local URL: http://localhost:8501
#   Network URL: http://192.168.x.x:8501

# First run downloads BAAI/bge-large-en-v1.5 model (~400MB, 1-2 min)
```

**ğŸ‰ Success!** 
- Open browser to: **http://localhost:8501**
- You should see the RAG Document Q&A interface

---

### ğŸ§ª Verify Installation

**Quick verification checklist:**

1. âœ… Python environment activated: `(venv)` in prompt
2. âœ… Dependencies installed: `pip show endee` shows version 0.1.8
3. âœ… Docker running: `docker ps` shows endee-server container
4. âœ… Endee responding: `curl http://localhost:8080/health`
5. âœ… Streamlit accessible: http://localhost:8501 loads
6. âœ… Can upload documents: Test with sample files in `data/documents/`
7. âœ… Can ask questions: Try "What is machine learning?"

---

### ğŸ”„ Managing the Application

**Stop everything:**
```bash
# Stop Streamlit: Press Ctrl+C in terminal

# Stop Endee (keeps data)
docker compose stop

# Stop Endee (removes data)
docker compose down
```

**Restart:**
```bash
# Start Endee
docker compose up -d

# Activate environment
.\venv\Scripts\Activate.ps1  # Windows
# source venv/bin/activate    # macOS/Linux

# Run app
streamlit run app.py
```

**Update code:**
```bash
git pull origin main
pip install -r requirements.txt --upgrade
docker compose pull  # Update Endee image
```

---

## ğŸ® Usage Guide

### 1ï¸âƒ£ **Upload Documents** (Tab 1)

- Click **"Browse files"** and select PDFs, DOCX, or TXT files
- Click **"ğŸš€ Upload & Index"**
- Wait for indexing to complete (1-2 min for 10 documents)

### 2ï¸âƒ£ **Configure LLM** (Sidebar)

**Option A: Groq API (Recommended - FREE!)**
- Select **"âš¡ Groq API (FREE)"**
- Paste your Groq API key
- Choose model: `llama-3.3-70b-versatile`
- Click **"Set Groq Provider"**

**Option B: OpenAI (Paid)**
- Select **"â˜ï¸ OpenAI API"**
- Paste your OpenAI API key
- Choose model: `gpt-3.5-turbo`

**Option C: Ollama (Local - Optional)**
- Install Ollama: https://ollama.com
- Run: `ollama serve`
- Pull model: `ollama pull llama3.2`
- Select **"ğŸš€ Ollama (GPU)"** or **"ğŸ’» Ollama (CPU)"**

### 3ï¸âƒ£ **Ask Questions** (Tab 2)

- Type your question: *"What is machine learning?"*
- Click **"ğŸ” Ask"**
- Get answer with source citations!

### 4ï¸âƒ£ **Test & Visualize** (Tab 4)

Try 6 interactive tests:
- **Embedding Similarity** - Compare word embeddings
- **Word Clustering** - Visualize semantic relationships
- **Semantic Search Quality** - Test retrieval accuracy
- **Context Window Impact** - Compare chunk sizes
- **Multi-Query Comparison** - Analyze multiple queries
- **Embedding Distribution** - Visualize database vectors

---

## ğŸ“Š Project Structure

```
assignment_rag/
â”œâ”€â”€ ğŸ“„ README.md              # This file - GitHub documentation
â”œâ”€â”€ ğŸ“„ GITHUB_SETUP.md        # GitHub repo setup guide
â”œâ”€â”€ ğŸ“‹ requirements.txt       # Python dependencies
â”œâ”€â”€ ğŸ³ docker-compose.yml     # Endee database config
â”œâ”€â”€ ğŸ”§ .env.example           # Environment template
â”œâ”€â”€ âš™ï¸ config.py              # Configuration management
â”œâ”€â”€ ğŸ¨ app.py                 # Streamlit web interface (4 tabs)
â”‚
â”œâ”€â”€ ğŸ“‚ Core Modules
â”‚   â”œâ”€â”€ document_processor.py # Load & chunk documents
â”‚   â”œâ”€â”€ embedding_engine.py   # Generate embeddings
â”‚   â”œâ”€â”€ vector_store.py       # Endee DB interface
â”‚   â”œâ”€â”€ rag_engine.py         # RAG orchestration
â”‚   â”œâ”€â”€ llm_manager.py        # Multi-LLM support (4 providers)
â”‚   â””â”€â”€ prompt_templates.py   # System prompts
â”‚
â”œâ”€â”€ ğŸ“‚ data/
â”‚   â”œâ”€â”€ documents/            # ğŸ“„ Your source documents (put files here!)
â”‚   â””â”€â”€ vectordb/             # ğŸ’¾ Endee database storage
â”‚
â””â”€â”€ ğŸ“‚ venv/                  # Python virtual environment
```

---

## âš™ï¸ Configuration

Edit `.env` file to customize:

### Step 2: Create Virtual Environment
```bash
python -m venv venv

# Windows
venv\Scripts\activate

# macOS/Linux
source venv/bin/activate
```

### Step 3: Install Dependencies
```bash
pip install -r requirements.txt
```

### Step 4: Configure Environment
```bash
# Copy example environment file
copy .env.example .env  # Windows
# cp .env.example .env  # macOS/Linux

# Edit .env and add your OpenAI API key
OPENAI_API_KEY=sk-your-actual-api-key-here
```

### Step 5: Prepare Documents
```bash
# Create documents directory
mkdir data
mkdir data\documents  # Windows
# mkdir -p data/documents  # macOS/Linux

# Add your documents to data/documents/
```

---

## ğŸš€ Usage

### Basic Usage

#### 1. Index Documents
```bash
python main.py --mode index --docs data/documents
```

#### 2. Query the System
```bash
python main.py --mode query --question "What is machine learning?"
```

#### 3. Interactive Mode
```bash
python main.py --mode interactive
```

### Programmatic Usage
```python
from rag_engine import RAGEngine

# Initialize RAG system
rag = RAGEngine()

# Index documents
rag.index_documents("data/documents")

# Query
response = rag.query("Explain neural networks")
print(response)
```

---

## âš™ï¸ Configuration

Edit `.env` file to customize:

```env
# LLM Providers (choose one or configure multiple)
GROQ_API_KEY=your_groq_key_here          # FREE from console.groq.com
OPENAI_API_KEY=your_openai_key_here      # Paid from platform.openai.com

# Embedding Settings
EMBEDDING_MODEL=sentence-transformers    # Local (free) or OpenAI (paid)

# RAG Settings
CHUNK_SIZE=500                           # Characters per chunk
CHUNK_OVERLAP=50                         # Overlap between chunks
TOP_K_RESULTS=5                          # Number of chunks to retrieve
```

---

## ğŸ”§ Advanced Features

### ğŸ¨ Streamlit Interface Tabs

**Tab 1: ğŸ“ Document Upload**
- Drag & drop files or browse
- Supports PDF, DOCX, TXT, MD
- Auto-deduplication (skips already-indexed files)
- Batch indexing with progress tracking

**Tab 2: ğŸ’¬ Ask Questions**
- Natural language query interface
- Conversation history
- Source citations with similarity scores
- Confidence threshold filtering

**Tab 3: âš™ï¸ Settings**
- LLM provider selection (Groq/OpenAI/Ollama)
- Model configuration
- Embedding options
- Custom prompt templates

**Tab 4: ğŸ§ª Interactive Tests**
- Test 1: Embedding Similarity (compare word vectors)
- Test 2: Word Clustering (t-SNE visualization)
- Test 3: Semantic Search Quality (retrieval metrics)
- Test 4: Context Window Impact (chunk size comparison)
- Test 5: Multi-Query Comparison (heatmap analysis)
- Test 6: Embedding Distribution (2D visualization)

### ğŸ¤– LLM Provider Options

| Provider | Cost | Speed | Models | Setup |
|----------|------|-------|--------|-------|
| **Groq** | FREE | âš¡ Fastest | Llama 3.3 70B, Mixtral 8x7B | Get key from console.groq.com |
| **OpenAI** | Paid | Fast | GPT-3.5, GPT-4 | Get key from platform.openai.com |
| **Ollama (GPU)** | FREE | Fast (local) | Llama, Mistral, Phi-3 | Install from ollama.com |
| **Ollama (CPU)** | FREE | Moderate | Same as GPU | No GPU required |

**ğŸ’¡ Recommended:** Start with **Groq** for best free experience!

---

## ğŸš¨ Troubleshooting

### Common Issues

**âŒ "ModuleNotFoundError"**
```bash
# Ensure venv is activated
.\venv\Scripts\activate  # Windows
source venv/bin/activate # macOS/Linux

# Reinstall dependencies
pip install -r requirements.txt
```

**âŒ "Docker not running"**
```bash
# Start Docker Desktop, then:
docker compose up -d

# Check status:
docker ps
```

**âŒ "Groq API Error"**
- Check your API key in `.env`
- Verify key at https://console.groq.com/keys
- Free tier has rate limits (30 requests/minute)

**âŒ "No documents indexed"**
- Put files in `data/documents/` folder
- Click "ğŸš€ Upload & Index" in Tab 1
- Wait for indexing to complete

**âŒ "Slow responses"**
- Try Groq instead of OpenAI (10x faster)
- Reduce `TOP_K_RESULTS` to 3
- Use smaller chunk sizes (300-400 chars)

---

## ğŸ“ˆ Performance Metrics

**Tested on 2,386 document chunks:**

| Metric | Value |
|--------|-------|
| **Indexing Time** | ~2 min (500 documents) |
| **Query Latency (P50)** | 1.8s with Groq, 2.5s with OpenAI |
| **Retrieval Accuracy** | 65-75% similarity scores |
| **Database Size** | ~27MB for 2,400 vectors (1024D BGE) |
| **Memory Usage** | ~800MB (BGE embeddings loaded in RAM) |

---



## ğŸ¯ Use Cases & Examples

### Example 1: Technical Documentation

**Question:** *"How do I configure Docker for this project?"*

**Answer:** 
> To configure Docker, run `docker compose up -d` from the project root. This starts the Endee vector database on port 8080...
> 
> **Sources:** 
> - `README.md` (similarity: 0.82)
> - `docker-compose.yml` (similarity: 0.75)

### Example 2: Research Papers

**Question:** *"What are the key findings about HNSW algorithm?"*

**Answer:**
> HNSW (Hierarchical Navigable Small World) achieves O(log n) search complexity with high recall rates. The paper demonstrates 10-100x speedup compared to brute-force search...
>
> **Sources:**
> - `vector_databases.md` (similarity: 0.88)

---

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“‹ FAQ

**Q: Do I need an OpenAI API key?**  
A: No! You can use Groq API (FREE) or Ollama (local). OpenAI is optional.

**Q: How much does Groq cost?**  
A: Completely FREE with generous rate limits (30 requests/minute).

**Q: Can I run this without internet?**  
A: Yes! Use Ollama for fully offline operation (requires downloading models first).

**Q: What file formats are supported?**  
A: PDF, DOCX, TXT, and Markdown (.md) files.

**Q: How many documents can I index?**  
A: Tested with 1000+ documents. Endee HNSW scales to millions of vectors.

**Q: Do files get re-indexed every time?**  
A: No! The system automatically skips already-indexed files (smart deduplication).

**Q: Can I delete indexed documents?**  
A: Yes, use the "ğŸ—‘ï¸ Clear Database" button in the sidebar or run `docker volume rm endee_data`.

---

## ğŸ“ Support

- ğŸ› **Issues:** [GitHub Issues](https://github.com/yourusername/assignment_rag/issues)
- ğŸ’¬ **Discussions:** [GitHub Discussions](https://github.com/yourusername/assignment_rag/discussions)
- ğŸ“§ **Email:** your.email@example.com

---

## ğŸ“œ License

MIT License - see [LICENSE](LICENSE) file for details.

---

## ğŸŒŸ Star History

If this project helped you, please â­ star it on GitHub!

---

## ğŸ”— Links

- **Live Demo:** [Coming Soon]
- **Video Tutorial:** [Coming Soon]
- **Blog Post:** [Coming Soon]

---

<div align="center">

**Built with â¤ï¸ using Endee, Streamlit, and Groq**

[â¬† Back to Top](#-intelligent-document-qa-system-with-rag)

</div>
